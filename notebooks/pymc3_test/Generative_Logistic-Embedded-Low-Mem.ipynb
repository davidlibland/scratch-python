{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import dok_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_dxs = 50\n",
    "num_findings = 20\n",
    "#num_hidden = 100\n",
    "avg_ddx_length = 5\n",
    "avg_num_findings = 15\n",
    "#ddx_max_length = 20 # this is the max length our graphical model can handle.\n",
    "sample_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def logit(p):\n",
    "    return np.log(p/(1.-p))\n",
    "logit_p_offset = logit(float(avg_num_findings)/num_findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Generate a sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "lam = 1.*avg_num_findings/num_findings\n",
    "_W = np.random.poisson(lam = lam, size=[num_dxs,num_findings])*1.\n",
    "_W*=np.random.gamma(shape = 1., size=[num_dxs, num_findings])\n",
    "#_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We generate random sparse cases, using a poisson distribution to randomly select the number of diagnoses and findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_random_case(num_dxs, num_findings, avg_ddx_length, w):\n",
    "    \"\"\"\n",
    "    Generates a random case.\n",
    "\n",
    "    Parameters:\n",
    "        num_dxs (:class:`int`): the number of possible diagnoses\n",
    "        num_findings (:class:`int`): the number of possible findings\n",
    "        avg_ddx_length (:class:`int`): the average number of diagnoses in a differential\n",
    "        W (:class:`np.array`): a weight matrix which correlates findings and diagnoses\n",
    "\n",
    "    Returns:\n",
    "        2-:class:`tuple` whose first component is a list of diagnoses, and whose second component is a list \n",
    "        of findings present.\n",
    "    \"\"\"\n",
    "\n",
    "    def invlogit(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "    \n",
    "\n",
    "    hidden_x = np.random.gamma(shape = 1.,size=num_dxs)\\\n",
    "                *np.random.poisson(lam = float(avg_ddx_length)/num_dxs, size=num_dxs)\n",
    "\n",
    "    y = np.dot(hidden_x,w)\n",
    "    findings_hot = np.random.binomial(n=1, p=invlogit(np.dot(hidden_x,w)+logit_p_offset))\n",
    "    findings = [i for i in range(num_findings) if findings_hot[i] == 1]\n",
    "\n",
    "    ddx_length = min(np.random.poisson(avg_ddx_length),num_dxs)\n",
    "\n",
    "    from heapq import nlargest\n",
    "    ddx = nlargest(ddx_length, range(num_dxs), key=lambda i: hidden_x[i])\n",
    "\n",
    "    return (ddx, findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batch = (generate_random_case(num_dxs,\n",
    "                              num_findings,\n",
    "                              avg_ddx_length,\n",
    "                              _W) for _ in xrange(sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(_W!=0,axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# n = 0.\n",
    "# for _,findings in batch:\n",
    "#     n+=len(findings)\n",
    "# n/sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ok, now we write code to process the data (so that we can feed it to our graphical model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _create_permutation_tensor(ddx):\n",
    "    ddx_length = len(ddx)\n",
    "    order = {big:o for o,big in enumerate(sorted(ddx))}\n",
    "    reord_proj_tensor = np.zeros([ddx_length,ddx_length])\n",
    "    for i in range(ddx_length):\n",
    "        reord_proj_tensor[order[ddx[i]],i] +=1\n",
    "    return reord_proj_tensor\n",
    "\n",
    "\n",
    "def _prepare_data(ddx, findings, num_dxs, num_findings):\n",
    "    \n",
    "    reord_proj_tensor = _create_permutation_tensor(ddx)\n",
    "\n",
    "    order = {big:o for o,big in enumerate(sorted(ddx))}\n",
    "    indicator_array = np.ma.ones([len(ddx),len(ddx)])\n",
    "    for i in range(0,len(ddx)):\n",
    "        for j in range(i):\n",
    "            indicator_array[i,order[ddx[j]]] = 0\n",
    "        indicator_array[i,order[ddx[i]]] = np.ma.masked\n",
    "\n",
    "    return (indicator_array, reord_proj_tensor, sorted(ddx), sorted(findings))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Code the probabilisitic model in pymc3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymc3 import Model, Bernoulli, Normal, find_MAP\n",
    "import theano.tensor as tt\n",
    "#from pymc3.math import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _low_mem_graphical_model(dx_order_indicator_array_data, reord_proj_tensor, findings_data):\n",
    "    \"\"\"\n",
    "    Builds the graphical model and ties the observable variables to the data. You can pass a batch of \n",
    "    :class:`int` `size` data; with :class:`int` `num_dxs` possible diagnoses, :class:`int` `num_findings`\n",
    "    possible findings, and :class:`int` `ddx_max_length` maximum diagnoses in a given differential.\n",
    "\n",
    "    Parameters:\n",
    "        dx_order_indicator_array_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`ddx_max_length`,`num_dxs`].\n",
    "        diff_tensor_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`num_dxs`,`ddx_max_length`,`num_dxs`].\n",
    "        findings_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`num_findings`]. \n",
    "\n",
    "    Returns:\n",
    "        4-:tuple: containing (x, dx_order, W, findings), where\n",
    "            x (:class:`Normal`): are hidden variables\n",
    "            dx_order (:class:`Bernoulli`): indicate the order of diagnoses in the differential\n",
    "            W (:class:`Normal`): is a matrix of parameters relating diagnoses to findings\n",
    "            findings (:class:`Bernoulli`): indicate the presence of findings\n",
    "\n",
    "    \"\"\"\n",
    "    # sigmoid function\n",
    "    def invlogit(x):\n",
    "        return 1. / (1 + tt.exp(-x))\n",
    "\n",
    "    ddx_length, num_dxs = dx_order_indicator_array_data.shape\n",
    "    num_findings = len(findings_data)\n",
    "\n",
    "    x = Normal('x', mu = 0.1, sd = 10, shape = num_dxs)\n",
    "    #V = Normal('V', mu=0, sd = 10, shape=[num_hidden,num_dxs],testval=np.random.randn(num_hidden,num_dxs)/num_dxs)\n",
    "    #x = tt.tensordot(hidden_vars, V, axes=[1,0])\n",
    "    if(ddx_length > 1):\n",
    "        dx_order_s_1 = tt.tensordot(x, reord_proj_tensor,axes=[0,0])\n",
    "        dx_order_s_1 = tt.reshape(dx_order_s_1,[ddx_length,1])\n",
    "        dx_order_s_2 = tt.reshape(x,[1,num_dxs])\n",
    "        dx_order_p = invlogit(tt.tile(dx_order_s_1,[1,num_dxs])-tt.tile(dx_order_s_2,[ddx_length,1]))\n",
    "        dx_order = Bernoulli(\"dx_order\", p=dx_order_p, observed=dx_order_indicator_array_data)\n",
    "    else:\n",
    "        dx_order = None\n",
    "    dx_extra = Bernoulli(\"seen\",p=invlogit(x),observed=1.)\n",
    "\n",
    "    W = Normal('W', mu=0, sd=10., shape=[num_dxs, num_findings])\n",
    "\n",
    "    findings_p = invlogit(tt.tensordot(x, W, axes=[0,0])+logit_p_offset)\n",
    "    findings = Bernoulli(\"findings\", findings_p, observed=np.ones([num_findings]))\n",
    "\n",
    "    return (x, dx_order, W, findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def invert_permutation(perm):\n",
    "    graph = enumerate(perm)\n",
    "    graph_range_sorted = sorted(graph,key=lambda x:x[1])\n",
    "    inverse_perm = zip(*graph_range_sorted)[0]\n",
    "    return inverse_perm\n",
    "\n",
    "def get_ordinal_permutation(list_of_distinct_ints):\n",
    "    \"\"\"\n",
    "    Returns the ordinal permutation for a list of distinct ints; i.e. the integers in the list are replaced by their \n",
    "    relative ordinals. For example, given `[25,6,7,-3]`, this function would return `[3,1,2,0]`. Complexity is n*log(n),\n",
    "    where n=len(list_of_distinct_ints).\n",
    "    \n",
    "    Parameters:\n",
    "        perm (:class:`list`): A list of distinct integers (in an arbitrary order).\n",
    "\n",
    "    Returns:\n",
    "        :class:`list` A list consisting of exactly the integers 0-n, with the same relative order\n",
    "            (where n=len(list_of_distinct_ints)).\n",
    "    \"\"\"\n",
    "    order = {big:o for o,big in enumerate(sorted(list_of_distinct_ints))}\n",
    "    ordinal_permutation = map(order.get,list_of_distinct_ints)\n",
    "    return ordinal_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "local_param_cache = dict()\n",
    "def cache_local_params(ddx,local_params_matrix):\n",
    "    if local_params_matrix.shape in local_param_cache:\n",
    "        return\n",
    "    ddx_ordinal_perm = get_ordinal_permutation(ddx)\n",
    "    local_param_cache[local_params_matrix.shape]=local_params_matrix[ddx_ordinal_perm,:]\n",
    "\n",
    "def retrieve_cached_local_params(ddx,findings):\n",
    "    shape = (len(ddx),len(findings))\n",
    "    cached_local_params = local_param_cache.get(shape)\n",
    "    if not (cached_local_params is None):\n",
    "        ordinal_perm = get_ordinal_permutation(ddx)\n",
    "        inverted_perm = invert_permutation(ordinal_perm)\n",
    "        return cached_local_params[inverted_perm,:]\n",
    "    return None\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "  Fit the model (aggregating individual MAP estimates - really this is the fist iteration of EM, but ok...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Model 1 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 279.481745\n",
      "         Iterations: 41\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 42\n",
      "ddx: [21, 13, 0, 1, 2]\n",
      "inferred: \n",
      "array([  5.56095031,   3.31019742,   1.14317997,   8.03212691,  11.00120884])\n",
      "[4, 3, 0, 1, 2]\n",
      "Map Estimate of W: \n",
      "array([[ 0.33635518,  0.33635518,  0.33635518,  0.33635518,  0.33635518,\n",
      "         0.33635518,  0.33635518,  0.33635518,  0.33635518,  0.33635518,\n",
      "         0.33635518,  0.33635518,  0.33635518,  0.33635518,  0.33635518,\n",
      "         0.33635518],\n",
      "       [ 0.24561437,  0.24561437,  0.24561437,  0.24561437,  0.24561437,\n",
      "         0.24561437,  0.24561437,  0.24561437,  0.24561437,  0.24561437,\n",
      "         0.24561437,  0.24561437,  0.24561437,  0.24561437,  0.24561437,\n",
      "         0.24561437],\n",
      "       [ 0.17007719,  0.17007719,  0.17007719,  0.17007719,  0.17007719,\n",
      "         0.17007719,  0.17007719,  0.17007719,  0.17007719,  0.17007719,\n",
      "         0.17007719,  0.17007719,  0.17007719,  0.17007719,  0.17007719,\n",
      "         0.17007719],\n",
      "       [ 0.10125474,  0.10125474,  0.10125474,  0.10125474,  0.10125474,\n",
      "         0.10125474,  0.10125474,  0.10125474,  0.10125474,  0.10125474,\n",
      "         0.10125474,  0.10125474,  0.10125474,  0.10125474,  0.10125474,\n",
      "         0.10125474],\n",
      "       [ 0.03491638,  0.03491638,  0.03491638,  0.03491638,  0.03491638,\n",
      "         0.03491638,  0.03491638,  0.03491638,  0.03491638,  0.03491638,\n",
      "         0.03491638,  0.03491638,  0.03491638,  0.03491638,  0.03491638,\n",
      "         0.03491638]])\n",
      "['x', 'dx_order_missing', 'W']\n",
      "Iteration 2\n",
      "Model 2 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 274.804728\n",
      "         Iterations: 40\n",
      "         Function evaluations: 41\n",
      "         Gradient evaluations: 41\n",
      "ddx: [22, 44, 26, 0]\n",
      "inferred: \n",
      "array([ 1.48695832,  9.68641264,  3.94127426,  6.57524647])\n",
      "[1, 3, 2, 0]\n",
      "Map Estimate of W: \n",
      "array([[ 0.41629391,  0.41629391,  0.41629391,  0.41629391,  0.41629391,\n",
      "         0.41629391,  0.41629391,  0.41629391,  0.41629391,  0.41629391,\n",
      "         0.41629391,  0.41629391,  0.41629391,  0.41629391,  0.41629391,\n",
      "         0.41629391,  0.41629391,  0.41629391,  0.41629391,  0.41629391],\n",
      "       [ 0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,\n",
      "         0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,\n",
      "         0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,\n",
      "         0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ,  0.2825967 ],\n",
      "       [ 0.16939943,  0.16939943,  0.16939943,  0.16939943,  0.16939943,\n",
      "         0.16939943,  0.16939943,  0.16939943,  0.16939943,  0.16939943,\n",
      "         0.16939943,  0.16939943,  0.16939943,  0.16939943,  0.16939943,\n",
      "         0.16939943,  0.16939943,  0.16939943,  0.16939943,  0.16939943],\n",
      "       [ 0.06389797,  0.06389797,  0.06389797,  0.06389797,  0.06389797,\n",
      "         0.06389797,  0.06389797,  0.06389797,  0.06389797,  0.06389797,\n",
      "         0.06389797,  0.06389797,  0.06389797,  0.06389797,  0.06389797,\n",
      "         0.06389797,  0.06389797,  0.06389797,  0.06389797,  0.06389797]])\n",
      "['x', 'dx_order_missing', 'W']\n",
      "Iteration 3\n",
      "Model 3 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 374.536195\n",
      "         Iterations: 42\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "ddx: [27, 45, 36, 39, 16, 0]\n",
      "inferred: \n",
      "array([  0.8678716 ,   2.83322918,  12.18026285,   6.9529553 ,\n",
      "         4.83015822,   9.31180577])\n",
      "[2, 5, 3, 4, 1, 0]\n",
      "Map Estimate of W: \n",
      "array([[ 0.28084663,  0.28084663,  0.28084663,  0.28084663,  0.28084663,\n",
      "         0.28084663,  0.28084663,  0.28084663,  0.28084663,  0.28084663,\n",
      "         0.28084663,  0.28084663,  0.28084663,  0.28084663,  0.28084663,\n",
      "         0.28084663,  0.28084663,  0.28084663],\n",
      "       [ 0.21474095,  0.21474095,  0.21474095,  0.21474095,  0.21474095,\n",
      "         0.21474095,  0.21474095,  0.21474095,  0.21474095,  0.21474095,\n",
      "         0.21474095,  0.21474095,  0.21474095,  0.21474095,  0.21474095,\n",
      "         0.21474095,  0.21474095,  0.21474095],\n",
      "       [ 0.16037328,  0.16037328,  0.16037328,  0.16037328,  0.16037328,\n",
      "         0.16037328,  0.16037328,  0.16037328,  0.16037328,  0.16037328,\n",
      "         0.16037328,  0.16037328,  0.16037328,  0.16037328,  0.16037328,\n",
      "         0.16037328,  0.16037328,  0.16037328],\n",
      "       [ 0.11144233,  0.11144233,  0.11144233,  0.11144233,  0.11144233,\n",
      "         0.11144233,  0.11144233,  0.11144233,  0.11144233,  0.11144233,\n",
      "         0.11144233,  0.11144233,  0.11144233,  0.11144233,  0.11144233,\n",
      "         0.11144233,  0.11144233,  0.11144233],\n",
      "       [ 0.06538418,  0.06538418,  0.06538418,  0.06538418,  0.06538418,\n",
      "         0.06538418,  0.06538418,  0.06538418,  0.06538418,  0.06538418,\n",
      "         0.06538418,  0.06538418,  0.06538418,  0.06538418,  0.06538418,\n",
      "         0.06538418,  0.06538418,  0.06538418],\n",
      "       [ 0.01999438,  0.01999438,  0.01999438,  0.01999438,  0.01999438,\n",
      "         0.01999438,  0.01999438,  0.01999438,  0.01999438,  0.01999438,\n",
      "         0.01999438,  0.01999438,  0.01999438,  0.01999438,  0.01999438,\n",
      "         0.01999438,  0.01999438,  0.01999438]])\n",
      "['x', 'dx_order_missing', 'W']\n",
      "Iteration 4\n",
      "Model 4 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 393.866406\n",
      "         Iterations: 42\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "ddx: [13, 25, 24, 19, 3, 0]\n",
      "inferred: \n",
      "array([  0.86827008,   2.83390555,  12.18223033,   4.83114373,\n",
      "         6.95425804,   9.31341851])\n",
      "[2, 5, 4, 3, 1, 0]\n",
      "Map Estimate of W: \n",
      "array([[ 0.28081829,  0.28081829,  0.28081829,  0.28081829,  0.28081829,\n",
      "         0.28081829,  0.28081829,  0.28081829,  0.28081829,  0.28081829,\n",
      "         0.28081829,  0.28081829,  0.28081829,  0.28081829,  0.28081829,\n",
      "         0.28081829,  0.28081829,  0.28081829,  0.28081829],\n",
      "       [ 0.21470227,  0.21470227,  0.21470227,  0.21470227,  0.21470227,\n",
      "         0.21470227,  0.21470227,  0.21470227,  0.21470227,  0.21470227,\n",
      "         0.21470227,  0.21470227,  0.21470227,  0.21470227,  0.21470227,\n",
      "         0.21470227,  0.21470227,  0.21470227,  0.21470227],\n",
      "       [ 0.16032863,  0.16032863,  0.16032863,  0.16032863,  0.16032863,\n",
      "         0.16032863,  0.16032863,  0.16032863,  0.16032863,  0.16032863,\n",
      "         0.16032863,  0.16032863,  0.16032863,  0.16032863,  0.16032863,\n",
      "         0.16032863,  0.16032863,  0.16032863,  0.16032863],\n",
      "       [ 0.11139409,  0.11139409,  0.11139409,  0.11139409,  0.11139409,\n",
      "         0.11139409,  0.11139409,  0.11139409,  0.11139409,  0.11139409,\n",
      "         0.11139409,  0.11139409,  0.11139409,  0.11139409,  0.11139409,\n",
      "         0.11139409,  0.11139409,  0.11139409,  0.11139409],\n",
      "       [ 0.06534638,  0.06534638,  0.06534638,  0.06534638,  0.06534638,\n",
      "         0.06534638,  0.06534638,  0.06534638,  0.06534638,  0.06534638,\n",
      "         0.06534638,  0.06534638,  0.06534638,  0.06534638,  0.06534638,\n",
      "         0.06534638,  0.06534638,  0.06534638,  0.06534638],\n",
      "       [ 0.01999654,  0.01999654,  0.01999654,  0.01999654,  0.01999654,\n",
      "         0.01999654,  0.01999654,  0.01999654,  0.01999654,  0.01999654,\n",
      "         0.01999654,  0.01999654,  0.01999654,  0.01999654,  0.01999654,\n",
      "         0.01999654,  0.01999654,  0.01999654,  0.01999654]])\n",
      "['x', 'dx_order_missing', 'W']\n",
      "Iteration 5\n",
      "Model 5 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 482.633323\n",
      "         Iterations: 42\n",
      "         Function evaluations: 43\n",
      "         Gradient evaluations: 43\n",
      "ddx: [40, 47, 14, 37, 0, 1, 2]\n",
      "inferred: \n",
      "array([  4.25497549,   2.44550813,   0.63220667,   8.17100655,\n",
      "         6.14387307,  13.23189779,  10.44315325])\n",
      "[5, 6, 3, 4, 0, 1, 2]\n",
      "Map Estimate of W: \n",
      "array([[ 0.24060501,  0.24060501,  0.24060501,  0.24060501,  0.24060501,\n",
      "         0.24060501,  0.24060501,  0.24060501,  0.24060501,  0.24060501,\n",
      "         0.24060501,  0.24060501,  0.24060501,  0.24060501,  0.24060501,\n",
      "         0.24060501,  0.24060501,  0.24060501,  0.24060501,  0.24060501],\n",
      "       [ 0.18991569,  0.18991569,  0.18991569,  0.18991569,  0.18991569,\n",
      "         0.18991569,  0.18991569,  0.18991569,  0.18991569,  0.18991569,\n",
      "         0.18991569,  0.18991569,  0.18991569,  0.18991569,  0.18991569,\n",
      "         0.18991569,  0.18991569,  0.18991569,  0.18991569,  0.18991569],\n",
      "       [ 0.14861298,  0.14861298,  0.14861298,  0.14861298,  0.14861298,\n",
      "         0.14861298,  0.14861298,  0.14861298,  0.14861298,  0.14861298,\n",
      "         0.14861298,  0.14861298,  0.14861298,  0.14861298,  0.14861298,\n",
      "         0.14861298,  0.14861298,  0.14861298,  0.14861298,  0.14861298],\n",
      "       [ 0.11176529,  0.11176529,  0.11176529,  0.11176529,  0.11176529,\n",
      "         0.11176529,  0.11176529,  0.11176529,  0.11176529,  0.11176529,\n",
      "         0.11176529,  0.11176529,  0.11176529,  0.11176529,  0.11176529,\n",
      "         0.11176529,  0.11176529,  0.11176529,  0.11176529,  0.11176529],\n",
      "       [ 0.07742285,  0.07742285,  0.07742285,  0.07742285,  0.07742285,\n",
      "         0.07742285,  0.07742285,  0.07742285,  0.07742285,  0.07742285,\n",
      "         0.07742285,  0.07742285,  0.07742285,  0.07742285,  0.07742285,\n",
      "         0.07742285,  0.07742285,  0.07742285,  0.07742285,  0.07742285],\n",
      "       [ 0.04450173,  0.04450173,  0.04450173,  0.04450173,  0.04450173,\n",
      "         0.04450173,  0.04450173,  0.04450173,  0.04450173,  0.04450173,\n",
      "         0.04450173,  0.04450173,  0.04450173,  0.04450173,  0.04450173,\n",
      "         0.04450173,  0.04450173,  0.04450173,  0.04450173,  0.04450173],\n",
      "       [ 0.01147436,  0.01147436,  0.01147436,  0.01147436,  0.01147436,\n",
      "         0.01147436,  0.01147436,  0.01147436,  0.01147436,  0.01147436,\n",
      "         0.01147436,  0.01147436,  0.01147436,  0.01147436,  0.01147436,\n",
      "         0.01147436,  0.01147436,  0.01147436,  0.01147436,  0.01147436]])\n",
      "['x', 'dx_order_missing', 'W']\n"
     ]
    }
   ],
   "source": [
    "W = dok_matrix((num_dxs,num_findings))\n",
    "N = dok_matrix((num_dxs,num_findings))\n",
    "cnt = 0\n",
    "for ddx, findings in batch:\n",
    "    if len(ddx)>0 and len(findings)>0:\n",
    "        cnt+=1\n",
    "        print(\"Iteration %d\"%cnt)\n",
    "        local_params = retrieve_cached_local_params(ddx,findings)\n",
    "        preped_data = _prepare_data(ddx, findings, num_dxs, num_findings)\n",
    "        dx_order_indicator_array, reord_proj_tensor, ddx_sorted, findings_sorted = preped_data\n",
    "        if local_params is None: \n",
    "            with Model() as med_model:\n",
    "                x, dx_order, W_loc, findings_rv = _low_mem_graphical_model(dx_order_indicator_array,\n",
    "                                                                  reord_proj_tensor,\n",
    "                                                                  findings_sorted)\n",
    "            print(\"Model %d Loaded\"%cnt)\n",
    "            map_estimate = find_MAP(model=med_model)\n",
    "            print(\"ddx: %r\"%ddx)\n",
    "            print(\"inferred: \\n%r\"%map_estimate['x'])\n",
    "            order = {big:o for o,big in enumerate(sorted(ddx))}\n",
    "            ddx_res = map(order.get,ddx)\n",
    "            print(ddx_res)\n",
    "            print(\"Map Estimate of W: \\n%r\"%map_estimate['W'][ddx_res,:])\n",
    "            #if not (local_params is None):\n",
    "            #    print(local_params-map_estimate['W'])\n",
    "            cache_local_params(ddx,map_estimate['W'])\n",
    "            local_params = map_estimate['W']\n",
    "            print(map_estimate.keys())\n",
    "        W[np.array(ddx_sorted)[:,np.newaxis],findings_sorted] += local_params\n",
    "        N[np.array(ddx_sorted)[:,np.newaxis],findings_sorted] += 1\n",
    "\n",
    "W[N != 0] /= N[N != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compare the estimate to the generating parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def _create_order_projection_tensor(ddx_max_length, ddx_extended):\n",
    "    num_dxs = len(ddx_extended)\n",
    "    assert ddx_max_length <= num_dxs, \"ddx_max_length: %d, num_dxs: %d\"%(ddx_max_length,num_dxs)\n",
    "    reord_proj_tensor = np.zeros([num_dxs,ddx_max_length])\n",
    "    for i in range(ddx_max_length):\n",
    "        reord_proj_tensor[ddx_extended[i],i] +=1\n",
    "    return reord_proj_tensor\n",
    "\n",
    "\n",
    "def _prepare_data(ddx,findings, num_dxs, num_findings, ddx_max_length):\n",
    "    ddx_max_length = min(ddx_max_length,num_dxs) # ensure ddx_max_length is a lower bound.\n",
    "\n",
    "    from itertools import ifilterfalse\n",
    "\n",
    "    ddx_extended = ddx + list(ifilterfalse(ddx.__contains__, range(num_dxs)))\n",
    "\n",
    "    findings_hot = np.zeros(num_findings, dtype=np.int)\n",
    "    findings_hot[findings] = 1\n",
    "    \n",
    "    reord_proj_tensor = _create_order_projection_tensor(ddx_max_length,ddxs)\n",
    "\n",
    "    indicator_array = np.ma.ones([ddx_max_length,num_dxs])\n",
    "    for i in range(0,ddx_max_length):\n",
    "        for j in range(i):\n",
    "            indicator_array[i,ddx[j]] = 0\n",
    "        indicator_array[i,ddx[i]] = np.ma.masked\n",
    "\n",
    "    indicator_array[cur_ddx_len:,:] = np.ma.masked\n",
    "\n",
    "    return (indicator_array, np.array(findings_hot_list), reord_proj_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def prediction_model(W,dx_order_indicator_array_data, reord_proj_tensor, findings_data):\n",
    "    num_dxs,num_findings = W.shape\n",
    "    \n",
    "    x = Normal('x', mu = 0.1, sd = 10, shape = num_dxs)\n",
    "    if(ddx_length > 1):\n",
    "        dx_order_s_1 = tt.tensordot(x, reord_proj_tensor,axes=[0,0])\n",
    "        dx_order_s_1 = tt.reshape(dx_order_s_1,[ddx_length,1])\n",
    "        dx_order_s_2 = tt.reshape(x,[1,num_dxs])\n",
    "        dx_order_p = invlogit(tt.tile(dx_order_s_1,[1,num_dxs])-tt.tile(dx_order_s_2,[ddx_length,1]))\n",
    "        dx_order = Bernoulli(\"dx_order\", p=dx_order_p, observed=dx_order_indicator_array_data)\n",
    "    else:\n",
    "        dx_order = None\n",
    "    dx_extra = Bernoulli(\"seen\",p=invlogit(x),observed=1.)\n",
    "\n",
    "    W = Normal('W', mu=0, sd=10., shape=[num_dxs, num_findings])\n",
    "\n",
    "    findings_p = invlogit(tt.tensordot(x, W, axes=[0,0])+logit_p_offset)\n",
    "    findings = Bernoulli(\"findings\", findings_p, observed=np.ones([num_findings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dx_order_indicator_array_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-12b53f444814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mddx_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_dxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx_order_indicator_array_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mnum_findings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfindings_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dx_order_indicator_array_data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with Model() as med_model_predict:\n",
    "    # sigmoid function\n",
    "    def invlogit(x):\n",
    "        return 1. / (1 + tt.exp(-x))\n",
    "\n",
    "    ddx_length, num_dxs = dx_order_indicator_array_data.shape\n",
    "    num_findings = len(findings_data)\n",
    "\n",
    "    x = Normal('x', mu = 0.1, sd = 10, shape = num_dxs)\n",
    "    #V = Normal('V', mu=0, sd = 10, shape=[num_hidden,num_dxs],testval=np.random.randn(num_hidden,num_dxs)/num_dxs)\n",
    "    #x = tt.tensordot(hidden_vars, V, axes=[1,0])\n",
    "    if(ddx_length > 1):\n",
    "        dx_order_s_1 = tt.tensordot(x, reord_proj_tensor,axes=[0,0])\n",
    "        dx_order_s_1 = tt.reshape(dx_order_s_1,[ddx_length,1])\n",
    "        dx_order_s_2 = tt.reshape(x,[1,num_dxs])\n",
    "        dx_order_p = invlogit(tt.tile(dx_order_s_1,[1,num_dxs])-tt.tile(dx_order_s_2,[ddx_length,1]))\n",
    "        dx_order = Bernoulli(\"dx_order\", p=dx_order_p, observed=dx_order_indicator_array_data)\n",
    "    else:\n",
    "        dx_order = None\n",
    "    dx_extra = Bernoulli(\"seen\",p=invlogit(x),observed=1.)\n",
    "\n",
    "    W = Normal('W', mu=0, sd=10., shape=[num_dxs, num_findings])\n",
    "\n",
    "    findings_p = invlogit(tt.tensordot(x, W, axes=[0,0])+logit_p_offset)\n",
    "    findings = Bernoulli(\"findings\", findings_p, observed=np.ones([num_findings]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comparisons = 1./(1+np.exp(-map_estimate['hidden_vars'].dot(map_estimate['W'])))-findings_data\n",
    "plt.hist(1./(1+np.exp(-map_estimate['hidden_vars'].dot(map_estimate['W'])))\n",
    "         -findings_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comparisons = 1./(1+np.exp(-np.einsum('ij,ijkl->ikl',np.dot(map_estimate['hidden_vars'],\n",
    "                                                           map_estimate['V']),diff_tensor_data)))\\\n",
    "                    -dx_order_indicator_array_data\n",
    "comparisons = comparisons.reshape([num_dxs,-1]).T\n",
    "\n",
    "plt.hist(comparisons)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymc3 import sample\n",
    "#from scipy import optimize\n",
    "\n",
    "with med_model:\n",
    "    # draw 2000 posterior samples\n",
    "    trace = sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymc3 import traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start = 10\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "comparisons = np.vstack([1./(1+np.exp(-hid.dot(w)))\n",
    "         -findings_data for hid,w in zip(trace['hidden_vars'][-start:],trace['W'][-start:])])\n",
    "               \n",
    "#comparison = chain.from_iterable(comparisons)\n",
    "\n",
    "plt.hist(comparisons)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comparisons = np.ma.vstack([1./(1+np.exp(-np.einsum('ij,ijkl->ikl',np.dot(hid,v),diff_tensor_data)))\n",
    "                    -dx_order_indicator_array_data \n",
    "               for hid,v in zip(trace['hidden_vars'][-start:],trace['V'][-start:])]).T\n",
    "comparisons = comparisons.reshape([num_dxs,-1]).T\n",
    "#comparisons = comparisons[comparisons.mask==False]\n",
    "\n",
    "\n",
    "plt.hist(comparisons)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/axes/_axes.py:6087: UserWarning: 2D hist input should be nsamples x nvariables;\n",
      " this looks transposed (shape is 1 x 1000)\n",
      "  '(shape is %d x %d)' % inp.shape[::-1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-49ba2b33fef3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0m_W\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mhist\u001b[0;34m(x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                       \u001b[0mhisttype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhisttype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m                       \u001b[0mrwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                       stacked=stacked, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3083\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6274\u001b[0m                 patch = _barfunc(bins[:-1]+boffset, height, width,\n\u001b[1;32m   6275\u001b[0m                                  \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6276\u001b[0;31m                                  color=c, **{bottom_kwarg: bottom})\n\u001b[0m\u001b[1;32m   6277\u001b[0m                 \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, left, height, width, bottom, **kwargs)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[0mymin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintervaly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m         \u001b[0mbar_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarContainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/libland/miniconda2/envs/pymc3_test/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36mautoscale_view\u001b[0;34m(self, tight, scalex, scaley)\u001b[0m\n\u001b[1;32m   2260\u001b[0m             \u001b[0mstickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msticky_edges\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2261\u001b[0m             \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2262\u001b[0;31m             \u001b[0my_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msticky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msticky\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstickies\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'log'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m                 \u001b[0mx_stickies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_stickies\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mxs\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12759e510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist((W-_W).reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.hist((0-_W).reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30169557,  0.30814383,  0.2971775 ,  0.39282128,  0.35273783,\n",
       "         0.36914026,  0.36439468,  0.33568688,  0.32581004,  0.41140806],\n",
       "       [ 0.41828603,  0.38017522,  0.33647847,  0.29991361,  0.3864158 ,\n",
       "         0.37781113,  0.37381359,  0.24548688,  0.35247719,  0.2986424 ],\n",
       "       [ 0.33245585,  0.29434949,  0.45746341,  0.37740589,  0.36203718,\n",
       "         0.37904643,  0.39881669,  0.38128621,  0.41995919,  0.30518777],\n",
       "       [ 0.38046228,  0.40998092,  0.32471794,  0.4036867 ,  0.37078999,\n",
       "         0.36995403,  0.39157169,  0.42570066,  0.33849418,  0.32115724],\n",
       "       [ 0.34801488,  0.4002106 ,  0.36276841,  0.38406521,  0.35900055,\n",
       "         0.37200588,  0.22883662,  0.39451811,  0.32019402,  0.40508064]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "        -0.00981045, -0.        , -0.63962823, -0.        ,  1.7958131 ],\n",
       "       [ 0.67279629,  0.3215445 ,  0.        , -0.59369557,  0.        ,\n",
       "         0.        , -0.20515441, -1.8712558 , -0.        , -0.        ],\n",
       "       [-0.        , -0.46299313,  2.75677448,  0.03720852, -0.        ,\n",
       "         0.        , -0.        , -0.        ,  1.01455315, -0.        ],\n",
       "       [ 0.48065189,  0.79646302, -0.        , -0.        , -0.        ,\n",
       "         0.        , -0.        ,  0.44392842, -0.        , -0.        ],\n",
       "       [ 0.        ,  0.76790261,  0.73802119, -0.        ,  0.        ,\n",
       "        -0.        , -1.19113878,  0.        ,  0.        ,  1.72832754]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.37421992,  0.37421992,  0.37421992,  0.37421992,  0.37421992],\n",
       "       [ 0.63261911,  0.63261911,  0.63261911,  0.63261911,  0.63261911],\n",
       "       [ 0.14934929,  0.14934929,  0.14934929,  0.14934929,  0.14934929]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_estimate['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x287259b90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrxpoUcuTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x286b75410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(x=_W,y=W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.14934929,  0.14934929,  0.14934929,  0.14934929,  0.14934929],\n",
       "       [ 0.63261911,  0.63261911,  0.63261911,  0.63261911,  0.63261911],\n",
       "       [ 0.37421992,  0.37421992,  0.37421992,  0.37421992,  0.37421992]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_estimate['W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 14.622457\n",
      "         Iterations: 27\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.02203819,  2.46359117])\n",
      "Map Estimat of W: \n",
      "array([[ 0.921826  ],\n",
      "       [ 0.37718303]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 21.071966\n",
      "         Iterations: 27\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.05762738,  2.4818141 ])\n",
      "Map Estimat of W: \n",
      "array([[ 0.91752672,  0.91752672],\n",
      "       [ 0.37594689,  0.37594689]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 27.521415\n",
      "         Iterations: 26\n",
      "         Function evaluations: 27\n",
      "         Gradient evaluations: 27\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.09259755,  2.49971178])\n",
      "Map Estimat of W: \n",
      "array([[ 0.91334417,  0.91334417,  0.91334417],\n",
      "       [ 0.37475556,  0.37475556,  0.37475556]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 33.970807\n",
      "         Iterations: 27\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.12705369,  2.51734188])\n",
      "Map Estimat of W: \n",
      "array([[ 0.90926635,  0.90926635,  0.90926635,  0.90926635],\n",
      "       [ 0.37357913,  0.37357913,  0.37357913,  0.37357913]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 40.420144\n",
      "         Iterations: 29\n",
      "         Function evaluations: 32\n",
      "         Gradient evaluations: 32\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.16090515,  2.5346727 ])\n",
      "Map Estimat of W: \n",
      "array([[ 0.9053007 ,  0.9053007 ,  0.9053007 ,  0.9053007 ,  0.9053007 ],\n",
      "       [ 0.37242672,  0.37242672,  0.37242672,  0.37242672,  0.37242672]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 46.869426\n",
      "         Iterations: 26\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.19450732,  2.55184258])\n",
      "Map Estimat of W: \n",
      "array([[ 0.90110329,  0.90110329,  0.90110329,  0.90110329,  0.90110329,\n",
      "         0.90110329],\n",
      "       [ 0.37182507,  0.37182507,  0.37182507,  0.37182507,  0.37182507,\n",
      "         0.37182507]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 53.318656\n",
      "         Iterations: 28\n",
      "         Function evaluations: 30\n",
      "         Gradient evaluations: 30\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.22698401,  2.5684979 ])\n",
      "Map Estimat of W: \n",
      "array([[ 0.89784337,  0.89784337,  0.89784337,  0.89784337,  0.89784337,\n",
      "         0.89784337,  0.89784337],\n",
      "       [ 0.36989883,  0.36989883,  0.36989883,  0.36989883,  0.36989883,\n",
      "         0.36989883,  0.36989883]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 59.767834\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.25933453,  2.58511928])\n",
      "Map Estimat of W: \n",
      "array([[ 0.89376172,  0.89376172,  0.89376172,  0.89376172,  0.89376172,\n",
      "         0.89376172,  0.89376172,  0.89376172],\n",
      "       [ 0.36971916,  0.36971916,  0.36971916,  0.36971916,  0.36971916,\n",
      "         0.36971916,  0.36971916,  0.36971916]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 66.216963\n",
      "         Iterations: 26\n",
      "         Function evaluations: 28\n",
      "         Gradient evaluations: 28\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.29125745,  2.60120851])\n",
      "Map Estimat of W: \n",
      "array([[ 0.89068513,  0.89068513,  0.89068513,  0.89068513,  0.89068513,\n",
      "         0.89068513,  0.89068513,  0.89068513,  0.89068513],\n",
      "       [ 0.36760676,  0.36760676,  0.36760676,  0.36760676,  0.36760676,\n",
      "         0.36760676,  0.36760676,  0.36760676,  0.36760676]])\n",
      "Model 40 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 72.666044\n",
      "         Iterations: 27\n",
      "         Function evaluations: 29\n",
      "         Gradient evaluations: 29\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.32276147,  2.61730424])\n",
      "Map Estimat of W: \n",
      "array([[ 0.88696625,  0.88696625,  0.88696625,  0.88696625,  0.88696625,\n",
      "         0.88696625,  0.88696625,  0.88696625,  0.88696625,  0.88696625],\n",
      "       [ 0.36658944,  0.36658944,  0.36658944,  0.36658944,  0.36658944,\n",
      "         0.36658944,  0.36658944,  0.36658944,  0.36658944,  0.36658944]])\n",
      "Model 41 Loaded\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 79.115077\n",
      "         Iterations: 29\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 31\n",
      "ddx: [1, 2]\n",
      "inferred: \n",
      "array([ 6.35390486,  2.63326511])\n",
      "Map Estimat of W: \n",
      "array([[ 0.88336906,  0.88336906,  0.88336906,  0.88336906,  0.88336906,\n",
      "         0.88336906,  0.88336906,  0.88336906,  0.88336906,  0.88336906,\n",
      "         0.88336906],\n",
      "       [ 0.36609252,  0.36609252,  0.36609252,  0.36609252,  0.36609252,\n",
      "         0.36609252,  0.36609252,  0.36609252,  0.36609252,  0.36609252,\n",
      "         0.36609252]])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 10 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-39816e343f26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inferred: \\n%r\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmap_estimate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Map Estimat of W: \\n%r\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mmap_estimate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfindings_sorted\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmap_estimate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfindings_sorted\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "ddx = [1,2]\n",
    "for i in range(15):\n",
    "    findings = range(i)\n",
    "    if len(ddx)>0 and len(findings)>0:\n",
    "        preped_data = _prepare_data(ddx, findings, num_dxs, num_findings)\n",
    "        dx_order_indicator_array, reord_proj_tensor, ddx_sorted, findings_sorted = preped_data\n",
    "        with Model() as med_model:\n",
    "            x, dx_order, W_loc, findings_rv = _low_mem_graphical_model(dx_order_indicator_array,\n",
    "                                                              reord_proj_tensor,\n",
    "                                                              findings_sorted)\n",
    "        print(\"Model %d Loaded\"%np.max(N))\n",
    "        map_estimate = find_MAP(model=med_model)\n",
    "        print(\"ddx: %r\"%ddx)\n",
    "        print(\"inferred: \\n%r\"%map_estimate['x'])\n",
    "        print(\"Map Estimat of W: \\n%r\"%map_estimate['W'])\n",
    "        W[np.array(ddx_sorted)[:,np.newaxis],findings_sorted] += map_estimate['W']\n",
    "        N[np.array(ddx_sorted)[:,np.newaxis],findings_sorted] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'dx_order_missing', 'W']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_estimate.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (16, 9)\t0.0653841752657\n",
      "  (19, 4)\t0.111394094767\n",
      "  (22, 19)\t0.416293907127\n",
      "  (44, 4)\t0.282596700658\n",
      "  (47, 9)\t0.189915685225\n",
      "  (21, 6)\t0.336355184172\n",
      "  (45, 9)\t0.214740945545\n",
      "  (36, 8)\t0.160373278177\n",
      "  (37, 13)\t0.11176528701\n",
      "  (0, 17)\t0.0453279354406\n",
      "  (24, 14)\t0.160328628193\n",
      "  (14, 1)\t0.148612978048\n",
      "  (25, 15)\t0.21470226536\n",
      "  (39, 11)\t0.111442331397\n",
      "  (26, 12)\t0.169399431815\n",
      "  (3, 2)\t0.0653463827733\n",
      "  (16, 0)\t0.0653841752657\n",
      "  (19, 13)\t0.111394094767\n",
      "  (44, 3)\t0.282596700658\n",
      "  (21, 15)\t0.336355184172\n",
      "  (45, 2)\t0.214740945545\n",
      "  (22, 12)\t0.416293907127\n",
      "  (14, 8)\t0.148612978048\n",
      "  (25, 16)\t0.21470226536\n",
      "  (39, 0)\t0.111442331397\n",
      "  :\t:\n",
      "  (21, 10)\t0.336355184172\n",
      "  (22, 1)\t0.416293907127\n",
      "  (14, 13)\t0.148612978048\n",
      "  (13, 8)\t0.263216331894\n",
      "  (26, 16)\t0.169399431815\n",
      "  (0, 3)\t0.0702777858368\n",
      "  (24, 0)\t0.160328628193\n",
      "  (3, 14)\t0.0653463827733\n",
      "  (1, 2)\t0.0445017347403\n",
      "  (2, 9)\t0.0231953724894\n",
      "  (40, 9)\t0.240605010041\n",
      "  (16, 18)\t0.0653841752657\n",
      "  (21, 19)\t0.336355184172\n",
      "  (44, 13)\t0.282596700658\n",
      "  (47, 0)\t0.189915685225\n",
      "  (45, 16)\t0.214740945545\n",
      "  (13, 1)\t0.280818294442\n",
      "  (37, 4)\t0.11176528701\n",
      "  (24, 7)\t0.160328628193\n",
      "  (27, 18)\t0.280846631712\n",
      "  (25, 6)\t0.21470226536\n",
      "  (39, 18)\t0.111442331397\n",
      "  (2, 0)\t0.0231953724894\n",
      "  (26, 5)\t0.169399431815\n",
      "  (27, 8)\t0.280846631712\n"
     ]
    }
   ],
   "source": [
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = W.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W[N != 0] /= N[N!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.01124445, -0.01194943, -0.00849899, -0.01124445, -0.01194943,\n",
       "         -0.01124445, -0.01124445, -0.01124445, -0.01124445, -0.01124445,\n",
       "         -0.01553402, -0.01124445, -0.01124445, -0.01124445, -0.01124445,\n",
       "         -0.01124445, -0.01124445, -0.00849899, -0.01124445, -0.01124445],\n",
       "        [-0.01821956,  0.        ,  0.        , -0.01821956,  0.        ,\n",
       "         -0.01821956, -0.01821956, -0.01821956, -0.01821956, -0.01821956,\n",
       "         -0.01821956, -0.01821956, -0.01821956, -0.01821956, -0.01821956,\n",
       "         -0.01821956, -0.01821956,  0.        , -0.01821956, -0.01821956],\n",
       "        [-0.00579884,  0.        ,  0.        , -0.00579884,  0.        ,\n",
       "         -0.00579884, -0.00579884, -0.00579884, -0.00579884, -0.00579884,\n",
       "         -0.00579884, -0.00579884, -0.00579884, -0.00579884, -0.00579884,\n",
       "         -0.00579884, -0.00579884,  0.        , -0.00579884, -0.00579884],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.06580408,  0.        ,  0.        , -0.06580408,  0.        ,\n",
       "         -0.06580408, -0.06580408, -0.06580408, -0.06580408, -0.06580408,\n",
       "          0.        , -0.06580408, -0.06580408, -0.06580408, -0.06580408,\n",
       "         -0.06580408, -0.06580408,  0.        , -0.06580408, -0.06580408],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W-W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(W1.toarray()-W.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,\n",
       "         2.,  2.,  2.,  2.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "         2.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.19.0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc3_test]",
   "language": "python",
   "name": "conda-env-pymc3_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
