{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Create some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_dxs = 5\n",
    "num_findings = 10\n",
    "avg_ddx_length = 3\n",
    "ddx_max_length = 5 # this is the max length our graphical model can handle.\n",
    "sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_W = np.random.randn(num_dxs, num_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_random_case(num_dxs, num_findings, avg_ddx_length, w):\n",
    "    \"\"\"\n",
    "    Generates a random case.\n",
    "\n",
    "    Parameters:\n",
    "        num_dxs (:class:`int`): the number of possible diagnoses\n",
    "        num_findings (:class:`int`): the number of possible findings\n",
    "        avg_ddx_length (:class:`int`): the average number of diagnoses in a differential\n",
    "        W (:class:`np.array`): a weight matrix which correlates findings and diagnoses\n",
    "\n",
    "    Returns:\n",
    "        2-:class:`tuple` whose first component is a list of diagnoses, and whose second component is a list \n",
    "        of findings present.\n",
    "    \"\"\"\n",
    "\n",
    "    def invlogit(x):\n",
    "        return 1. / (1 + np.exp(-x))\n",
    "\n",
    "    hidden_x = np.random.laplace(loc=0., scale=1., size=num_dxs)\n",
    "\n",
    "    findings_hot = np.random.binomial(n=1, p=invlogit(np.dot(hidden_x,w)))\n",
    "    findings = [i for i in range(num_findings) if findings_hot[i] == 1]\n",
    "\n",
    "    ddx_length = np.random.poisson(avg_ddx_length)\n",
    "\n",
    "    from heapq import nlargest\n",
    "    ddx = nlargest(ddx_length, range(num_dxs), key=lambda i: hidden_x[i])\n",
    "\n",
    "    return (ddx, findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "minibatch = []\n",
    "for _ in range(sample_size):\n",
    "    minibatch.append(generate_random_case(num_dxs,\n",
    "                                          num_findings,\n",
    "                                          avg_ddx_length,\n",
    "                                          _W))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ok, now we write code to process the data (so that we can feed it to our graphical model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _create_diff_tensor_a(minibatch_size, num_dxs):\n",
    "    return np.tile(np.eye(num_dxs)[:, :, np.newaxis] - np.eye(num_dxs)[:, np.newaxis, :], [minibatch_size, 1, 1, 1])\n",
    "\n",
    "def _create_reordered_diff_tensor_a(ddx_max_length, ddxs_extended):\n",
    "    minibatch_size = len(ddxs_extended)\n",
    "    num_dxs = len(ddxs_extended[0])\n",
    "    assert ddx_max_length <= num_dxs, \"ddx_max_length: %d, num_dxs: %d\"%(ddx_max_length,num_dxs)\n",
    "    diff_tensor = np.zeros([minibatch_size,num_dxs,ddx_max_length,num_dxs])\n",
    "    for n in range(minibatch_size):\n",
    "        assert len(ddxs_extended[n]) == num_dxs,\\\n",
    "            \"for each n, need len(ddxs_extended[n]) == len(ddxs_extended[0]), but \\n\"+\\\n",
    "            \"len(ddxs_extended[%d])==%d! and len(ddxs_extended[0])==%d\"\\\n",
    "            %(n,len(ddxs_extended[n]),len(ddxs_extended[0]))\n",
    "        for i in range(ddx_max_length):\n",
    "            for j in range(num_dxs):\n",
    "                diff_tensor[n,ddxs_extended[n][i],i,j] +=1\n",
    "        for i in range(num_dxs):\n",
    "            for j in range(ddx_max_length):\n",
    "                diff_tensor[n,ddxs_extended[n][i],j,i] -=1\n",
    "    return diff_tensor\n",
    "\n",
    "\n",
    "def _create_first_axes_reordered_diff_tensor_a(ddx_max_length, ddxs_extended):\n",
    "    minibatch_size = len(ddxs_extended)\n",
    "    num_dxs = len(ddxs_extended[0])\n",
    "    assert ddx_max_length <= num_dxs, \"ddx_max_length: %d, num_dxs: %d\"%(ddx_max_length,num_dxs)\n",
    "    diff_tensor = np.zeros([minibatch_size,num_dxs,ddx_max_length,num_dxs])\n",
    "    for n in range(minibatch_size):\n",
    "        assert len(ddxs_extended[n]) == num_dxs,\\\n",
    "            \"for each n, need len(ddxs_extended[n]) == len(ddxs_extended[0]), but \\n\"+\\\n",
    "            \"len(ddxs_extended[%d])==%d! and len(ddxs_extended[0])==%d\"\\\n",
    "            %(n,len(ddxs_extended[n]),len(ddxs_extended[0]))\n",
    "        for i in range(ddx_max_length):\n",
    "            for j in range(num_dxs):\n",
    "                diff_tensor[n,ddxs_extended[n][i],i,j] +=1\n",
    "        for i in range(num_dxs):\n",
    "            for j in range(ddx_max_length):\n",
    "                diff_tensor[n,i,j,i] -=1\n",
    "    return diff_tensor\n",
    "\n",
    "def _create_order_projection_tensor(ddx_max_length, ddxs_extended):\n",
    "    minibatch_size = len(ddxs_extended)\n",
    "    num_dxs = len(ddxs_extended[0])\n",
    "    assert ddx_max_length <= num_dxs, \"ddx_max_length: %d, num_dxs: %d\"%(ddx_max_length,num_dxs)\n",
    "    reord_proj_tensor = np.zeros([minibatch_size,num_dxs,ddx_max_length])\n",
    "    for n in range(minibatch_size):\n",
    "        assert len(ddxs_extended[n]) == num_dxs,\\\n",
    "            \"for each n, need len(ddxs_extended[n]) == len(ddxs_extended[0]), but \\n\"+\\\n",
    "            \"len(ddxs_extended[%d])==%d! and len(ddxs_extended[0])==%d\"\\\n",
    "            %(n,len(ddxs_extended[n]),len(ddxs_extended[0]))\n",
    "        for i in range(ddx_max_length):\n",
    "            reord_proj_tensor[n,ddxs_extended[n][i],i] +=1\n",
    "    return reord_proj_tensor\n",
    "\n",
    "\n",
    "def _prepare_data_batch(data, num_dxs, num_findings, ddx_max_length):\n",
    "    ddx_max_length = min(ddx_max_length,num_dxs) # ensure ddx_max_length is a lower bound.\n",
    "\n",
    "    from itertools import ifilterfalse\n",
    "    \n",
    "    ddxs = []\n",
    "    ddxs_extended = []\n",
    "    ddx_lens = []\n",
    "    findings_hot_list = []\n",
    "    for ddx, findings in data:\n",
    "        ddx_extended = ddx + list(ifilterfalse(ddx.__contains__, range(num_dxs)))\n",
    "        ddxs.append(ddx_extended)\n",
    "        ddx_lens.append(min(ddx_max_length, len(ddx)))\n",
    "\n",
    "        findings_hot = np.zeros(num_findings, dtype=np.int)\n",
    "        findings_hot[findings] = 1\n",
    "        findings_hot_list.append(findings_hot)\n",
    "\n",
    "    N = len(ddxs)\n",
    "    reordered_diff_tensor = _create_first_axes_reordered_diff_tensor_a(ddx_max_length,ddxs)\n",
    "    \n",
    "    reord_proj_tensor = _create_order_projection_tensor(ddx_max_length,ddxs)\n",
    "\n",
    "    indicator_array = np.ma.ones([N,ddx_max_length,num_dxs])\n",
    "    for n in range(N):\n",
    "        for i in range(0,ddx_max_length):\n",
    "            for j in range(i):\n",
    "                indicator_array[n,i,ddxs[n][j]] = 0\n",
    "            indicator_array[n,i,ddxs[n][i]] = np.ma.masked\n",
    "\n",
    "    for n,cur_ddx_len in enumerate(ddx_lens):\n",
    "        indicator_array[n,cur_ddx_len:,:] = np.ma.masked\n",
    "\n",
    "    return (indicator_array, reordered_diff_tensor, np.array(findings_hot_list), reord_proj_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = minibatch\n",
    "preped_data = _prepare_data_batch(data,num_dxs,num_findings,ddx_max_length)\n",
    "dx_order_indicator_array_data, diff_tensor_data, findings_data, reord_proj_tensor = preped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Code the probabilisitic model in pymc3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pymc3 import Model, Categorical, Bernoulli, Normal, Laplace, Dirichlet, Uniform, find_MAP\n",
    "import theano.tensor as tt\n",
    "#from pymc3.math import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _build_graphical_model(dx_order_indicator_array_data, diff_tensor_data, findings_data):\n",
    "        \"\"\"\n",
    "        Builds the graphical model and ties the observable variables to the data. You can pass a batch of \n",
    "        :class:`int` `size` data; with :class:`int` `num_dxs` possible diagnoses, :class:`int` `num_findings`\n",
    "        possible findings, and :class:`int` `ddx_max_length` maximum diagnoses in a given differential.\n",
    "    \n",
    "        Parameters:\n",
    "            dx_order_indicator_array_data (:class:`np.array`): should be of shape \n",
    "                [`size`,`ddx_max_length`,`num_dxs`].\n",
    "            diff_tensor_data (:class:`np.array`): should be of shape \n",
    "                [`size`,`num_dxs`,`ddx_max_length`,`num_dxs`].\n",
    "            findings_data (:class:`np.array`): should be of shape \n",
    "                [`size`,`num_findings`]. \n",
    "    \n",
    "        Returns:\n",
    "            4-:tuple: containing (x, dx_order, W, findings), where\n",
    "                x (:class:`Normal`): are hidden variables\n",
    "                dx_order (:class:`Bernoulli`): indicate the order of diagnoses in the differential\n",
    "                W (:class:`Normal`): is a matrix of parameters relating diagnoses to findings\n",
    "                findings (:class:`Bernoulli`): indicate the presence of findings\n",
    "    \n",
    "        \"\"\"\n",
    "        # sigmoid function\n",
    "        def invlogit(x):\n",
    "            return 1. / (1 + tt.exp(-x))\n",
    "\n",
    "        size, ddx_max_length, num_dxs = dx_order_indicator_array_data.shape\n",
    "        num_findings = findings_data.shape[1]\n",
    "\n",
    "        x = Normal(\"x\", mu=0, sd=10, shape=[size, num_dxs])\n",
    "        dx_order_p = invlogit(tt.batched_tensordot(x, diff_tensor_data,axes=[1,1]))\n",
    "        dx_order = Bernoulli(\"dx_order\", p=dx_order_p, observed=dx_order_indicator_array_data)\n",
    "\n",
    "        W = Normal('W', mu=0., sd=10., shape=[num_dxs, num_findings])\n",
    "        \n",
    "        findings_p = invlogit(tt.tensordot(x, W, axes=[1,0]))\n",
    "        findings = Bernoulli(\"findings\", findings_p, observed=findings_data)\n",
    "\n",
    "        return (x, dx_order, W, findings)\n",
    "\n",
    "def _sp_build_graphical_model(dx_order_indicator_array_data, reord_proj_tensor, findings_data):\n",
    "    \"\"\"\n",
    "    Builds the graphical model and ties the observable variables to the data. You can pass a batch of \n",
    "    :class:`int` `size` data; with :class:`int` `num_dxs` possible diagnoses, :class:`int` `num_findings`\n",
    "    possible findings, and :class:`int` `ddx_max_length` maximum diagnoses in a given differential.\n",
    "\n",
    "    Parameters:\n",
    "        dx_order_indicator_array_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`ddx_max_length`,`num_dxs`].\n",
    "        diff_tensor_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`num_dxs`,`ddx_max_length`,`num_dxs`].\n",
    "        findings_data (:class:`np.array`): should be of shape \n",
    "            [`size`,`num_findings`]. \n",
    "\n",
    "    Returns:\n",
    "        4-:tuple: containing (x, dx_order, W, findings), where\n",
    "            x (:class:`Normal`): are hidden variables\n",
    "            dx_order (:class:`Bernoulli`): indicate the order of diagnoses in the differential\n",
    "            W (:class:`Normal`): is a matrix of parameters relating diagnoses to findings\n",
    "            findings (:class:`Bernoulli`): indicate the presence of findings\n",
    "\n",
    "    \"\"\"\n",
    "    # sigmoid function\n",
    "    def invlogit(x):\n",
    "        return 1. / (1 + tt.exp(-x))\n",
    "\n",
    "    size, ddx_max_length, num_dxs = dx_order_indicator_array_data.shape\n",
    "    num_findings = findings_data.shape[1]\n",
    "\n",
    "    x = Normal(\"x\", mu=0, sd=10, shape=[size, num_dxs])\n",
    "    dx_order_s_1 = tt.batched_tensordot(x, reord_proj_tensor,axes=[1,1])\n",
    "    dx_order_s_1 = tt.reshape(dx_order_s_1,[size,ddx_max_length,1])\n",
    "    dx_order_s_2 = tt.reshape(x,[size,1,num_dxs])\n",
    "    dx_order_p = invlogit(tt.tile(dx_order_s_1,[1,1,num_dxs])-tt.tile(dx_order_s_2,[1,ddx_max_length,1]))\n",
    "    dx_order = Bernoulli(\"dx_order\", p=dx_order_p, observed=dx_order_indicator_array_data)\n",
    "\n",
    "    W = Normal('W', mu=0., sd=10., shape=[num_dxs, num_findings])\n",
    "\n",
    "    findings_p = invlogit(tt.tensordot(x, W, axes=[1,0]))\n",
    "    findings = Bernoulli(\"findings\", findings_p, observed=findings_data)\n",
    "\n",
    "    return (x, dx_order, W, findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with Model() as med_model:\n",
    "    x, dx_order, W, findings = _sp_build_graphical_model(dx_order_indicator_array_data,\n",
    "                                                      reord_proj_tensor,\n",
    "                                                      findings_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "  Fit the model (using a MAP estimate - really this is EM, but ok...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 400.545116\n",
      "         Iterations: 242\n",
      "         Function evaluations: 260\n",
      "         Gradient evaluations: 258\n"
     ]
    }
   ],
   "source": [
    "map_estimate = find_MAP(model=med_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Compare the estimate to the generating parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbkkqxnBLUjH/D3+0SjddS8kIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b21810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(1./(1+np.exp(-map_estimate['x'].dot(map_estimate['W'])))\n",
    "         -findings_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116580710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "comparison = 1./(1+np.exp(-np.einsum('ij,ijkl->ikl',map_estimate['x'],diff_tensor_data)))-dx_order_indicator_array_data\n",
    "plt.hist(comparison.reshape([-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_estimate['dx_order_missing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
